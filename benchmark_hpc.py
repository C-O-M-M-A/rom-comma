#  BSD 3-Clause License.
# 
#  Copyright (c) 2019-2023 Robert A. Milton. All rights reserved.
# 
#  Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
# 
#  1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
# 
#  2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the
#     documentation and/or other materials provided with the distribution.
# 
#  3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this
#     software without specific prior written permission.
# 
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
#  THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR
#  CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
#  PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
#  LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
#  EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


""" Benchmark GPR and GSA for known test functions. """

from __future__ import annotations
import argparse
import tarfile
import os

from romcomma.base.definitions import *
from romcomma import user

#: Parameters to generate data from test functions.
K: int = 2  #: The number of Folds in a new repository.
Ms: Tuple[int, ...] = (5, 7, 9, 11, 13, 15, 17, 19)  #: The number of inputs.
Ns: Tuple[int, ...] = (1460, 1680, 2000, 3000, 4000, )   #: The number of
# samples (datapoints).
DOE: user.sample.DOE.Method = user.sample.DOE.latin_hypercube  #: The Design Of Experiments to generate the sample inputs.
FUNCTION_VECTOR: user.functions.Vector = user.functions.ALL  #: The function vector to apply to the inputs generated by the DOE.
NOISE_MAGNITUDES: Tuple[float] = (0.2, 0.1, 0.075, 0.05, 0.025, 0.01, 0.005, 0.0025, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.2, 1.5, 2.0, 5.0,
                                  10.0)   #: The noise-to-signal ratio, which is equal to the StdDev of the noise added to the normalised function output.
IS_NOISE_COVARIANT: bool = False  #: Whether the Gaussian noise applied to the outputs is statistically independent between outputs.
IS_NOISE_VARIANCE_DETERMINED: bool = True  #: Whether the noise variance is fixed or random.
ROTATIONS = {'': None}  #: Dict of rotations applied to the input basis after the function vector has been sampled.
#: Parameters to run Gaussian Process Regression.
IS_GPR_READ: bool | None = None  #: Whether to read the GPR model from file.
IS_GPR_COVARIANT: bool | None = False  #: Whether the GPR likelihood is covariant.
IS_GPR_ISOTROPIC: bool | None = False  #: Whether the GPR kernel is isotropic.
#: Parameters to run Global Sensitivity Analysis.
GSA_KINDS: List[user.run.GSA.Kind] = user.run.GSA.ALL_KINDS  #: A list of the kinds of GSA to do.
IS_GSA_ERROR_CALCULATED: bool = True  #: Whether to calculate the GSA standard error
IS_GSA_ERROR_PARTIAL: bool = False  #: Whether the calculated the GSA standard error is partial


def run(args: argparse.Namespace, root: str | Path) -> Path:
    """ Run benchmark data generation and/or Gaussian Process Regression and/or Global Sensitivity Analysis, and collect the results.

    Args:
        args: The command line arguments passed to this module.
        root: The root folder.
    Returns: The root path written to.
    """
    with user.contexts.Environment('Test', device='GPU' if args.gpu else 'CPU'):
        KIND_NAMES = [kind.name.lower() for kind in GSA_KINDS]
        for noise_magnitude in NOISE_MAGNITUDES:
            for M in Ms:
                for N in Ns:
                    noise_variance = user.sample.GaussianNoise.Variance(len(FUNCTION_VECTOR), noise_magnitude, IS_NOISE_COVARIANT, IS_NOISE_VARIANCE_DETERMINED)
                    for rotation_name, rotation in ROTATIONS.items():
                        ext = rotation_name + f'.{args.ext}' if args.ext else ''
                        ext = ext if ext else None
                        with user.contexts.Timer(f'M={M}, N={N}, noise={noise_magnitude}, ext={ext}', is_inline=False):

                            # Get data sample, either from function or file.
                            if args.function:
                                repo = (user.sample.Function(root, DOE, FUNCTION_VECTOR, N, M, noise_variance, ext, True)
                                        .into_K_folds(K).rotate_folds(rotation).repo)
                            else:
                                repo = user.sample.Function(root, DOE, FUNCTION_VECTOR, N, M, noise_variance, ext, False).repo

                            # Run GPR, or collect stored GPR models.
                            if args.gpr:
                                models = user.run.gpr(name='gpr', repo=repo, is_read=IS_GPR_READ, is_covariant=IS_GPR_COVARIANT,
                                                      is_isotropic=IS_GPR_ISOTROPIC, ignore_exceptions=args.ignore)
                            else:
                                models = [path.name for path in repo.folder.glob('gpr.*')]

                            # Collect GPR results from GPR models.
                            user.results.Collect({'test': {'header': [0, 1]}, 'test_summary': {'header': [0, 1], 'index_col': 0}},
                                                 {repo.folder / model: {'model': model} for model in models},
                                                 args.ignore).from_folders(repo.folder / 'gpr', True)
                            user.results.Collect({'variance': {}, 'log_marginal': {}},
                                                 {f'{repo.folder / model}/likelihood': {'model': model} for model in models},
                                                 args.ignore).from_folders((repo.folder / 'gpr') / 'likelihood', True)
                            user.results.Collect({'variance': {}, 'lengthscales': {}},
                                                 {f'{repo.folder / model}/kernel': {'model': model} for model in models},
                                                 args.ignore).from_folders((repo.folder / 'gpr') / 'kernel', True)

                            # Run GSA and collect results, or just collect results.
                            if args.gsa:
                                user.run.gsa('gpr', repo, is_covariant=IS_GPR_COVARIANT, is_isotropic=False, kinds=GSA_KINDS,
                                             is_error_calculated=IS_GSA_ERROR_CALCULATED, ignore_exceptions=args.ignore,
                                             is_T_partial=IS_GSA_ERROR_PARTIAL)
                                user.results.Collect({'S': {}, 'V': {}} | ({'T': {}, 'W': {}} if IS_GSA_ERROR_CALCULATED else {}),
                                                     {f'{repo.folder / model}/gsa/{kind_name}': {'model': model, 'kind': kind_name}
                                                      for kind_name in KIND_NAMES for model in models},
                                                     args.ignore).from_folders((repo.folder / 'gsa'), True)
                            else:
                                user.results.Collect({'S': {}, 'V': {}} | ({'T': {}, 'W': {}} if IS_GSA_ERROR_CALCULATED else {}),
                                                     {f'{repo.folder / model}/gsa/{kind_name}': {'model': model, 'kind': kind_name}
                                                      for kind_name in KIND_NAMES for model in models},
                                                     True).from_folders((repo.folder / 'gsa'), True)
    return root


if __name__ == '__main__':

    # Get the command line arguments.
    parser = argparse.ArgumentParser(description='A program to benchmark GPR and GSA against a (vector) test function.')
    # Control flow arguments.
    parser.add_argument("-f", "--function", action='store_true', help="Flag to sample the test function to generate test data.")
    parser.add_argument("-r", "--gpr", action='store_true', help="Flag to run Gaussian process regression.")
    parser.add_argument("-s", "--gsa", action='store_true', help="Flag to run global sensitivity analysis.")
    parser.add_argument("-i", "--ignore", action='store_true', help="Flag to ignore exceptions.")
    parser.add_argument("-g", "--gpu", action='store_true', help="Flag to run on a GPU instead of CPU.")
    # Optional parameter setters
    parser.add_argument("-K", "--folds", help="The number of k-folds to use (negative to omit improper fold). Defaults to 2.", type=int)
    parser.add_argument("-M", "--input_dim", help="The input dimension M. Defaults to [7, 10, 12, 15, 18].", type=int)
    parser.add_argument("-c", "--is_noise_covariant", action='store_true', help="Whether noise (uncertainty) is covariant across outputs.")
    parser.add_argument("-C", "--is_gpr_covariant", action='store_true', help="Whether GPR (likelihood) is covariant across outputs.")
    # File locations
    parser.add_argument("-e", "--ext", help="The extension appended to each store name.", type=str)
    parser.add_argument("-t", "--tar", help="Outputs a .tar.gz file to path.", type=str)
    parser.add_argument("root", help="The path of the root folder to house all data repositories.", type=str)
    args = parser.parse_args()  # Convert arguments to argparse.Namespace.

    # Run the code.
    K = args.folds if args.folds else K
    Ms = (args.input_dim,) if args.input_dim else Ms
    IS_NOISE_COVARIANT = args.is_noise_covariant if args.is_noise_covariant else IS_NOISE_COVARIANT
    IS_GPR_COVARIANT = args.is_gpr_covariant if args.is_gpr_covariant else IS_GPR_COVARIANT
    root = Path(args.root)
    print(f'Root path is {run(args, root)}')
    # Tar outputs
    if args.tar:
        tar_path = Path(args.tar)
        tar_path.parents[0].mkdir(parents=True, exist_ok=True)
        with tarfile.open(tar_path, "w:gz") as tar:
            for item in os.listdir(args.root):
                tar.add(Path(args.root, item), arcname=item)
