#  BSD 3-Clause License.
# 
#  Copyright (c) 2019-2023 Robert A. Milton. All rights reserved.
# 
#  Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
# 
#  1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
# 
#  2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the
#     documentation and/or other materials provided with the distribution.
# 
#  3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this
#     software without specific prior written permission.
# 
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
#  THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR
#  CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
#  PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
#  LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
#  EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

""" Create a Repository by sampling a test function, adding noise, and optionally rotating the input basis """
from __future__ import annotations
import argparse
import tarfile
import os

from romcomma.base.definitions import *
from romcomma import run


#: Parameters to generate data from test functions.
K: int = 2   #: The number of Folds in a new repository.
Ms: Tuple[int,...] = (7, 10, 13, 18)   #: The number of inputs.
Ns: Tuple[int,...] = (10000, 7000, 5000, 2000, 1680,)   #: The number of
# samples (datapoints).
DOE: run.sample.DOE.Method = run.sample.DOE.latin_hypercube    #: The Design Of Experiments to generate the sample inputs.
FUNCTION_VECTOR: run.function.Vector = run.function.ALL   #: The function vector to apply to the inputs generated by the DOE.
NOISE_MAGNITUDES: Tuple[float] = (0.2, 0.1, 0.075, 0.05, 0.025, 0.01, 0.005, 0.0025, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.2, 1.5, 2.0, 5.0,
                                  10.0)   #: The noise-to-signal ratio, which is equal to the StdDev of the noise added to the normalised function output.
IS_NOISE_COVARIANT: Tuple[bool] = (False, True)   #: Whether the Gaussian noise applied to the outputs is statistically independent between outputs.
IS_NOISE_VARIANCE_RANDOM: Tuple[bool] = (False,)    #: Whether the noise variance is stochastic or fixed.
ROTATIONS = (None,)     #: Rotation applied to the input basis after the function vector has been sampled.
#: Parameters to run Gaussian Process Regression.
IS_GPR_READ: bool | None = None    #: Whether to read the GPR model from file.
IS_GPR_COVARIANT: bool | None = False   #: Whether the GPR likelihood is covariant.
IS_GPR_ISOTROPIC: bool | None = False    #: Whether the GPR kernel is isotropic.
#: Parameters to run Global Sensitivity Analysis.
GSA_KINDS: List[run.summarised.GSA.Kind] = run.summarised.GSA.ALL_KINDS    #: A list of the kinds of GSA to do.
IS_GSA_ERROR_CALCULATED: bool = True    #: Whether to calculate the GSA standard error
IS_GSA_ERROR_PARTIAL: bool = False    #: Whether the calculated the GSA standard error is partial


def benchmark(args: argparse.Namespace) -> Path:
    """ Run benchmark data generation and/or Gaussian Process Regression and/or Global Sensitivity Analysis, and collect the results.

    Args:
        args: The command line arguments passed to this module
    Returns: The root path written to.
    """
    with run.context.Environment('Test', device='GPU' if args.gpu else 'CPU'):
        root = Path(args.root)
        KIND_NAMES = [kind.name.lower() for kind in GSA_KINDS]
        for noise_magnitude in NOISE_MAGNITUDES:
            for is_noise_covariant in IS_NOISE_COVARIANT:
                for is_noise_variance_random in IS_NOISE_VARIANCE_RANDOM:
                    for M in Ms:
                        for N in Ns:
                            noise_variance = run.sample.GaussianNoise.Variance(len(FUNCTION_VECTOR), noise_magnitude, is_noise_covariant,
                                                                             is_noise_variance_random)
                            ext = 0
                            for rotation in ROTATIONS:
                                with run.context.Timer(f'M={M}, N={N}, noise={noise_magnitude}, is_noise_covariant={is_noise_covariant}, ' +
                                                   f'is_noise_variance_random={is_noise_variance_random}, ext={ext}', is_inline=False):
                                    if args.data:
                                        repo = (run.sample.Function(root, DOE, FUNCTION_VECTOR, N, M, noise_variance, str(ext), True)
                                                .into_K_folds(K).rotate_folds(rotation).repo)
                                    else:
                                        repo = run.sample.Function(root, DOE, FUNCTION_VECTOR, N, M, noise_variance, str(ext), False).repo
                                    if args.gpr:
                                        models = run.summarised.gpr(name='gpr', repo=repo, is_read=IS_GPR_READ, is_covariant=IS_GPR_COVARIANT,
                                                                    is_isotropic=IS_GPR_ISOTROPIC, ignore_exceptions=args.ignore)
                                    else:
                                        models = [path.name for path in repo.folder.glob('gpr.*')]
                                    run.results.Collect({'test': {'header': [0, 1]}, 'test_summary': {'header': [0, 1], 'index_col': 0}},
                                                    {repo.folder / model: {'model': model} for model in models},
                                                    args.ignore).from_folders(repo.folder / 'gpr', True)
                                    run.results.Collect({'variance': {}, 'log_marginal': {}},
                                                    {f'{repo.folder / model}/likelihood': {'model': model} for model in models},
                                                    args.ignore).from_folders((repo.folder / 'gpr') / 'likelihood', True)
                                    run.results.Collect({'variance': {}, 'lengthscales': {}},
                                                    {f'{repo.folder / model}/kernel': {'model': model} for model in models},
                                                    args.ignore).from_folders((repo.folder / 'gpr') / 'kernel', True)
                                    if args.gsa:
                                        run.summarised.gsa('gpr', repo, is_covariant=IS_GPR_COVARIANT, is_isotropic=False, kinds=GSA_KINDS,
                                                       is_error_calculated=IS_GSA_ERROR_CALCULATED, ignore_exceptions=args.ignore,
                                                           is_T_partial=IS_GSA_ERROR_PARTIAL)
                                        run.results.Collect({'S': {}, 'V': {}} | ({'T': {}, 'W': {}} if IS_GSA_ERROR_CALCULATED else {}),
                                                        {f'{repo.folder / model}/gsa/{kind_name}': {'model': model, 'kind': kind_name}
                                                         for kind_name in KIND_NAMES for model in models},
                                                        args.ignore).from_folders((repo.folder / 'gsa'), True)
                                    else:
                                        run.results.Collect({'S': {}, 'V': {}} | ({'T': {}, 'W': {}} if IS_GSA_ERROR_CALCULATED else {}),
                                                            {f'{repo.folder / model}/gsa/{kind_name}': {'model': model, 'kind': kind_name}
                                                             for kind_name in KIND_NAMES for model in models},
                                                            True).from_folders((repo.folder / 'gsa'), True)
                                ext += 1
    return root

if __name__ == '__main__':
    # Gets the command line arguments
    parser = argparse.ArgumentParser()
    parser.add_argument("-d", "--data", action='store_true', help="Flag to run data generation and storage.")
    parser.add_argument("-r", "--gpr", action='store_true', help="Flag to run Gaussian process regression.")
    parser.add_argument("-s", "--gsa", action='store_true', help="Flag to run global sensitivity analysis.")
    parser.add_argument("-g", "--gpu", action='store_true', help="Flag to run on a GPU instead of CPU.")
    parser.add_argument("-i", "--ignore", action='store_true', help="Flag to ignore exceptions.")
    parser.add_argument("-t", "--tar", help="Outputs a .tar.gz file to path.", type=str)
    parser.add_argument("root", help="The path of the root folder to house all data repositories.", type=str)
    args = parser.parse_args()  # Convert arguments to dictionary
    # Runs the code
    print(f'Root path is {benchmark(args)}')
    # Tarring outputs
    if args.tar:
        # Gets the tar path and ensure we have a directory
        tar_path = Path(args.tar)
        tar_path.parents[0].mkdir(parents=True, exist_ok=True)
        # Puts everything in the ROOT folder inside the tar file
        with tarfile.open(tar_path, "w:gz") as tar:
            for item in os.listdir(args.root):
                tar.add(Path(args.root, item), arcname=item)




